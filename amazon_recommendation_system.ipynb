# %% [markdown]
# # Amazon Beauty Products Recommendation System
# 
# ## Project Overview
# This notebook implements a collaborative filtering recommendation system for Amazon Beauty products using Singular Value Decomposition (SVD).
# 
# ### Objectives:
# 1. Analyze customer rating patterns
# 2. Identify popular products
# 3. Implement collaborative filtering
# 4. Generate personalized recommendations
# 
# ### Dataset:
# - **Source**: Amazon Beauty Products Dataset
# - **Size**: 2,023,070 ratings
# - **Features**: UserId, ProductId, Rating, Timestamp

# %% [markdown]
# ## 1. Setup and Configuration

# %%
import sys
import os

# Add project directory to path
sys.path.append('../')

# Import project modules
from config import Config
from data_processor import DataProcessor
from recommender import Recommender
from utils import plot_popular_products, print_recommendations, setup_plotting

# Standard imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import TruncatedSVD

# Setup plotting
setup_plotting()
print("Setup complete!")

# %% [markdown]
# ## 2. Data Loading and Exploration

# %%
# Initialize data processor
processor = DataProcessor()

# Load data with sampling
df = processor.load_data(sample_size=Config.SAMPLE_SIZE)
df.head()

# %%
# Dataset information
print("Dataset Information:")
print("=" * 40)
print(f"Total records: {len(df):,}")
print(f"Unique users: {df['UserId'].nunique():,}")
print(f"Unique products: {df['ProductId'].nunique():,}")
print(f"Date range: {pd.to_datetime(df['Timestamp'], unit='s').min()} to {pd.to_datetime(df['Timestamp'], unit='s').max()}")
print(f"Average rating: {df['Rating'].mean():.2f}")
print(f"Rating distribution:\n{df['Rating'].value_counts().sort_index()}")

# %%
# Rating distribution visualization
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Rating count plot
rating_counts = df['Rating'].value_counts().sort_index()
bars = ax1.bar(rating_counts.index.astype(str), rating_counts.values, color='lightcoral')
ax1.set_title('Rating Distribution', fontsize=14, fontweight='bold')
ax1.set_xlabel('Rating Score', fontsize=12)
ax1.set_ylabel('Count', fontsize=12)

# Add value labels
for bar in bars:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 5,
             f'{int(height):,}', ha='center', va='bottom')

# Rating histogram
ax2.hist(df['Rating'], bins=5, edgecolor='black', alpha=0.7, color='lightgreen')
ax2.set_title('Rating Histogram', fontsize=14, fontweight='bold')
ax2.set_xlabel('Rating', fontsize=12)
ax2.set_ylabel('Frequency', fontsize=12)
ax2.set_xticks(range(1, 6))

plt.tight_layout()
plt.show()

# %% [markdown]
# ## 3. Popularity Analysis

# %%
# Get top popular products
popular_products = processor.get_popular_products(n=20)
print("Top 20 Most Popular Products:")
print("=" * 60)
print(popular_products)

# %%
# Visualize popular products
fig = plot_popular_products(popular_products, n=20)

# %% [markdown]
# ## 4. Collaborative Filtering Implementation

# %%
# Create utility matrix
print("Creating utility matrix...")
utility_matrix = processor.create_utility_matrix()
print(f"Utility matrix shape: {utility_matrix.shape}")

# %%
# Show sample of utility matrix
print("Sample of utility matrix (first 5 rows and columns):")
sample_matrix = utility_matrix.iloc[:5, :5]
display(sample_matrix)

# %%
# Check sparsity of the matrix
total_elements = utility_matrix.shape[0] * utility_matrix.shape[1]
non_zero_elements = (utility_matrix != 0).sum().sum()
sparsity = 100 * (1 - non_zero_elements / total_elements)
print(f"Matrix sparsity: {sparsity:.2f}%")
print(f"Non-zero elements: {non_zero_elements:,}")
print(f"Total elements: {total_elements:,}")

# %% [markdown]
# ## 5. Model Training with SVD

# %%
# Transpose matrix for item-based filtering
X = utility_matrix.T
print(f"Transposed matrix shape: {X.shape}")

# %%
# Initialize and train recommender
recommender = Recommender(svd_components=Config.SVD_COMPONENTS)
recommender.fit(X)
print(f"SVD components: {Config.SVD_COMPONENTS}")
print(f"Variance explained: {recommender.svd.explained_variance_ratio_.sum():.2%}")

# %% [markdown]
# ## 6. Generating Recommendations

# %%
# Demo product for recommendations
demo_product = Config.DEMO_PRODUCT_ID

# Check if demo product exists
if demo_product not in X.index:
    print(f"Note: Demo product '{demo_product}' not in sampled data.")
    print("Using first product in dataset instead.")
    demo_product = X.index[0]

print(f"Generating recommendations for product: {demo_product}")

# %%
# Get recommendations
recommendations = recommender.recommend(
    product_id=demo_product,
    n_recommendations=15
)

# Display recommendations
print_recommendations(demo_product, recommendations)

# %%
# Get detailed correlation scores
correlation_scores = recommender.get_recommendation_scores(demo_product)

print(f"\nTop 10 most correlated products with {demo_product}:")
print("=" * 70)
top_correlations = correlation_scores.head(11)  # Includes the product itself
for idx, (product_id, score) in enumerate(top_correlations.items()):
    if product_id == demo_product:
        print(f"{idx:2d}. {product_id} (Current Product) - Correlation: {score:.4f}")
    else:
        print(f"{idx:2d}. {product_id} - Correlation: {score:.4f}")

# %%
# Visualize correlation distribution
fig, ax = plt.subplots(figsize=(10, 6))

# Plot histogram of correlation scores
ax.hist(correlation_scores.values, bins=50, alpha=0.7, color='steelblue', edgecolor='black')
ax.axvline(x=Config.CORRELATION_THRESHOLD, color='red', linestyle='--', linewidth=2, 
           label=f'Threshold ({Config.CORRELATION_THRESHOLD})')
ax.set_xlabel('Correlation Coefficient', fontsize=12)
ax.set_ylabel('Frequency', fontsize=12)
ax.set_title('Distribution of Product Correlations', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# %% [markdown]
# ## 7. Testing with Multiple Products

# %%
def test_multiple_products(product_ids, n_recommendations=5):
    """Test recommendation system with multiple products"""
    results = {}
    
    for product_id in product_ids:
        if product_id in X.index:
            recommendations = recommender.recommend(
                product_id=product_id,
                n_recommendations=n_recommendations
            )
            results[product_id] = recommendations
        else:
            print(f"Product {product_id} not found in dataset")
            
    return results

# %%
# Test with sample products
sample_products = list(X.index[:3])  # First 3 products in the dataset
test_results = test_multiple_products(sample_products, n_recommendations=3)

print("Test Results for Sample Products:")
print("=" * 60)
for product_id, recs in test_results.items():
    print(f"\nProduct: {product_id}")
    print(f"Recommendations: {recs}")

# %% [markdown]
# ## 8. Model Evaluation Metrics

# %%
def calculate_model_metrics(recommender, utility_matrix):
    """Calculate basic model evaluation metrics"""
    X = utility_matrix.T
    
    # Calculate reconstruction error
    decomposed_matrix = recommender.svd.transform(X)
    reconstructed_matrix = recommender.svd.inverse_transform(decomposed_matrix)
    
    # Calculate Frobenius norm of reconstruction error
    reconstruction_error = np.linalg.norm(X - reconstructed_matrix, 'fro')
    
    # Calculate variance explained
    variance_explained = recommender.svd.explained_variance_ratio_.sum()
    
    metrics = {
        'reconstruction_error': reconstruction_error,
        'variance_explained': variance_explained,
        'n_components': recommender.svd.n_components,
        'sparsity': 100 * (1 - (X != 0).sum().sum() / (X.shape[0] * X.shape[1]))
    }
    
    return metrics

# %%
# Calculate and display metrics
metrics = calculate_model_metrics(recommender, utility_matrix)

print("Model Performance Metrics:")
print("=" * 40)
for key, value in metrics.items():
    if key == 'variance_explained':
        print(f"{key.replace('_', ' ').title()}: {value:.2%}")
    elif key == 'sparsity':
        print(f"{key.replace('_', ' ').title()}: {value:.2f}%")
    else:
        print(f"{key.replace('_', ' ').title()}: {value:.4f}")

# %% [markdown]
# ## 9. Conclusion and Business Insights

# %%
print("KEY INSIGHTS:")
print("=" * 40)
print("1. Popular Products: Certain beauty products have significantly more reviews")
print("   indicating higher popularity or longer market presence.")
print()
print("2. Rating Pattern: Most ratings are positive (4-5 stars), common in beauty products.")
print()
print("3. Recommendation System: Successfully identifies correlated products")
print("   based on user purchase patterns.")
print()
print("4. Business Value: Can increase cross-selling by recommending related")
print("   products to customers.")

# %% [markdown]
# ## 10. Future Improvements

# %%
improvements = [
    "1. Incorporate additional features (product categories, price points)",
    "2. Implement hybrid recommendation (content + collaborative filtering)",
    "3. Add temporal analysis to track changing preferences",
    "4. Incorporate explicit user feedback on recommendations",
    "5. Scale to full dataset with distributed computing",
    "6. A/B testing of recommendation algorithms",
    "7. Real-time recommendation updates",
    "8. Personalization based on user demographics"
]

print("Future Improvements:")
print("=" * 40)
for item in improvements:
    print(f"â€¢ {item}")

# %% [markdown]
# ## Summary
# This notebook demonstrates a complete recommendation system pipeline from data loading to model deployment. The system effectively identifies popular products and provides personalized recommendations using collaborative filtering with SVD.
